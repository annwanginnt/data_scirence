{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the data exploration phase by:\n",
    "\n",
    "Plotting boxplots for continuous variables against the output variable (Churn).\n",
    "Using groupby() to check proportions for categorical variables against the output variable.\n",
    "First, let's examine the continuous variables by plotting boxplots with Churn on the x-axis and each continuous variable on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# List of continuous variables to be plotted\n",
    "continuous_columns = ['Age', 'Month_1_Spend', 'Month_2_Spend', 'Month_3_Spend', 'Month_4_Spend', 'Month_5_Spend']\n",
    "\n",
    "# Plotting boxplots for each continuous variable\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i, col in enumerate(continuous_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(x='Churn', y=col, data=df)\n",
    "    plt.title(f'Boxplot of {col} vs Churn')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age: There seems to be a slight difference in age distribution between churned and retained customers. The median age for churned customers is slightly higher.\n",
    "Monthly Spends: The spread of data for monthly spends seems to vary between churned and retained customers. For some months, churned customers tend to have a higher median spend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking proportions for 'Location' against 'Churn'\n",
    "location_churn = df.groupby('Location')['Churn'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Checking proportions for 'Device' against 'Churn'\n",
    "device_churn = df.groupby('Device')['Churn'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "location_churn, device_churn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location:\n",
    "Customers from 'Australia' and 'Great Britain' have no churn (100% retention).\n",
    "'Canada' and 'US' have higher churn rates, with around 82% of customers churning.\n",
    "Device:\n",
    "Android users have a higher churn rate (approximately 84%).\n",
    "iOS users have a more balanced distribution with approximately 50.6% churn rate and 49.3% retention rate.\n",
    "These insights indicate that the Location and Device variables may have some influence on customer churn and should be considered in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning continuous variables to transform them into categorical ones.\n",
    "Creating dummy variables for categorical variables using one-hot encoding.\n",
    "Defining new metrics, if applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning 'Age' column into age groups\n",
    "bins = [20, 30, 40, 50, 60, 70]\n",
    "labels = ['20-29', '30-39', '40-49', '50-59', '60-69']\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Creating dummy variables for 'Location', 'Device', and 'Age_Group' columns\n",
    "df = pd.get_dummies(df, columns=['Location', 'Device', 'Age_Group'], drop_first=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Age column has been binned into age groups, and dummy variables have been created for Location, Device, and Age_Group columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking proportions for 'Age_Group' against 'Churn'\n",
    "age_group_churn = df.groupby('Age')['Churn'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Checking proportions for dummy variables against 'Churn'\n",
    "location_dummy_churn = df.groupby('Location_US')['Churn'].value_counts(normalize=True).unstack().fillna(0)\n",
    "device_dummy_churn = df.groupby('Device_iOS')['Churn'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "age_group_churn, location_dummy_churn, device_dummy_churn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the insights based on the proportions of the engineered features with the output variable (Churn):\n",
    "\n",
    "Age:\n",
    "\n",
    "Younger customers (ages 20-25) have a 100% churn rate, indicating they always churn.\n",
    "Ages around 26-30 have a churn rate of about 66-71%.\n",
    "There's a variability in churn rates for the middle-aged group (30-60).\n",
    "Older customers (ages 64-65) have a 100% retention rate, indicating they never churn.\n",
    "Location (US vs. Others):\n",
    "\n",
    "Customers from the US have a higher churn rate (approx. 82%) compared to customers from other locations (approx. 61%).\n",
    "Device (iOS vs. Android):\n",
    "\n",
    "Android users have a higher churn rate (approx. 84%).\n",
    "iOS users have a more balanced distribution, with a churn rate of approximately 50.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the models, we need to prepare the data by splitting it into training and testing sets and scaling the features. After that, we'll proceed with building the baseline models. Let's start with data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Defining the features and target variable\n",
    "X = df.drop(columns=['Churn', 'Unnamed: 0', 'CustomerID', 'Age'])\n",
    "y = df['Churn']\n",
    "\n",
    "# Splitting the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been split into training and testing sets, with 8,000 samples in the training set and 2,000 samples in the test set. The features have also been scaled.\n",
    "\n",
    "Next, we'll build baseline models using various algorithms:\n",
    "\n",
    "Logistic Regression\n",
    "Naive Bayes\n",
    "KNN (K-Nearest Neighbors)\n",
    "SVM (Support Vector Machines)\n",
    "Decision Tree\n",
    "We'll use cross-validation to run each model 10 times and calculate an average performance based on the F1 score. Let's start by building and evaluating these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initializing the models\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "naive_bayes = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "models = [logreg, naive_bayes, knn, svm, decision_tree]\n",
    "model_names = ['Logistic Regression', 'Naive Bayes', 'KNN', 'SVM', 'Decision Tree']\n",
    "f1_scores = []\n",
    "\n",
    "# Performing cross-validation for each model and calculating average F1 scores\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train_scaled, y_train, cv=10, scoring='f1').mean()\n",
    "    f1_scores.append(score)\n",
    "\n",
    "# Combining the model names and F1 scores into a dataframe\n",
    "model_performance = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Average F1 Score': f1_scores\n",
    "}).sort_values(by='Average F1 Score', ascending=False)\n",
    "\n",
    "model_performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the SVM model took a considerable amount of time to run using cross-validation, causing an automatic interrupt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree model has the highest F1 score among the baseline models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll optimize the Decision Tree model with a focus on precision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Setting up the parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(1, 50),\n",
    "    'min_samples_split': randint(2, 100),\n",
    "    'min_samples_leaf': randint(1, 100),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Running RandomizedSearchCV with 100 iterations\n",
    "random_search = RandomizedSearchCV(decision_tree, param_distributions=param_dist, n_iter=100, \n",
    "                                   scoring='precision', cv=10, verbose=1, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters from RandomizedSearchCV\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "best_params, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized Decision Tree model, with a focus on precision, has the following best hyperparameters:\n",
    "\n",
    "Criterion: Entropy\n",
    "Maximum Depth: 44\n",
    "Maximum Features: None (all features will be considered when looking for the best split)\n",
    "Minimum Samples Leaf: 5 (The smallest number of samples required to be at a leaf node)\n",
    "Minimum Samples Split: 69 (The smallest number of samples required to split an internal node)\n",
    "With these optimized parameters, the model achiev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's evaluate the model on the test data and check various performance metrics, such as precision, recall, F1 score, ROC AUC, and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# Predicting using the optimized Decision Tree model\n",
    "y_pred = random_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculating performance metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "performance_metrics = {\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'ROC AUC': roc_auc,\n",
    "    'Accuracy': accuracy\n",
    "}\n",
    "\n",
    "performance_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has achieved a high precision of approximately 96.95%, which aligns with our focus on prioritizing precision. The other metrics also indicate strong performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Exploration:\n",
    "\n",
    "The dataset was imported and checked for missing values and data types. There were no missing values, and data types appeared appropriate.\n",
    "Exploration revealed that younger customers tend to churn more, while older customers have a higher retention rate. Additionally, customers from the US and Android users have higher churn rates compared to others.\n",
    "Feature Engineering:\n",
    "\n",
    "The Age column was binned into age groups to create categorical variables, and one-hot encoding was used to convert the Location and Device columns to dummy variables.\n",
    "Modeling:\n",
    "\n",
    "Baseline models were built using Logistic Regression, Naive Bayes, KNN, and Decision Tree. The Decision Tree had the highest F1 score among these.\n",
    "The Decision Tree model was then optimized with a focus on precision using hyperparameter tuning. The optimized model achieved a precision of approximately 96.95% on the test data.\n",
    "Decisions and Business Objective:\n",
    "\n",
    "Precision was prioritized to ensure that resources are targeted effectively without being wasted on false positives. The high precision achieved means that when the model predicts a customer will churn, it's highly accurate in that prediction.\n",
    "In conclusion, the optimized Decision Tree model can be a valuable tool for predicting customer churn with high precision, allowing the business to target interventions more effectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
